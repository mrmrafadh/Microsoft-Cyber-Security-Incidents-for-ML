{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.stats as stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import joblib\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data in chunks to handle large file size\n",
    "chunk_size = 500000  # Adjust chunk size for memory efficiency\n",
    "chunks = []\n",
    "\n",
    "# Reading the dataset in chunks\n",
    "for chunk in pd.read_csv(r'C:/Users/User/Desktop/MDT 28/Assignments/Microsoft -Classifying Cybersecurity Incidents/GUIDE_Test.csv/GUIDE_Test.csv', chunksize=chunk_size, low_memory=False):\n",
    "    # Optimize memory usage by downcasting data types\n",
    "    for col in chunk.select_dtypes(include=['int64', 'float64']).columns:\n",
    "        chunk[col] = pd.to_numeric(chunk[col], downcast='integer')\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Concatenate all chunks into a single DataFrame\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "del chunks  # Free up memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Id',\n",
    " 'OrgId',\n",
    " 'IncidentId',\n",
    " 'AlertId',\n",
    " 'DetectorId',\n",
    " 'AlertTitle',\n",
    " 'DeviceId',\n",
    " 'Sha256',\n",
    " 'IpAddress',\n",
    " 'Url',\n",
    " 'Category',\n",
    " 'IncidentGrade',\n",
    " 'EntityType',\n",
    " 'EvidenceRole']\n",
    "\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4147992, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               0\n",
       "OrgId            0\n",
       "IncidentId       0\n",
       "AlertId          0\n",
       "DetectorId       0\n",
       "AlertTitle       0\n",
       "DeviceId         0\n",
       "Sha256           0\n",
       "IpAddress        0\n",
       "Url              0\n",
       "Category         0\n",
       "IncidentGrade    0\n",
       "EntityType       0\n",
       "EvidenceRole     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_col = ['Category', 'IncidentGrade', 'EntityType', 'EvidenceRole']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoders have been applied to the test data.\n"
     ]
    }
   ],
   "source": [
    "# Load the encoders dictionary from the pickle file\n",
    "with open('label_encoders.pkl', 'rb') as file:\n",
    "    loaded_encoders = pickle.load(file)\n",
    "\n",
    "# Apply the encoders to the test data\n",
    "for column in cat_col:\n",
    "    try:\n",
    "        df[column] = loaded_encoders[column].transform(df[column])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(\"Encoders have been applied to the test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('IncidentGrade', axis = 1)\n",
    "y = df['IncidentGrade']\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('best_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9257820344308735\n",
      "Recall: 0.9203978879535909\n",
      "F1 Score: 0.9180690192423975\n",
      "Precision: 0.915933680899041\n"
     ]
    }
   ],
   "source": [
    "test_data_pred = model.predict(X)\n",
    "\n",
    "accuracy = accuracy_score(y, test_data_pred)\n",
    "recall = recall_score(y, test_data_pred, average='macro')  # Adjust for binary/multiclass\n",
    "f1 = f1_score(y, test_data_pred, average='macro')          # Adjust for binary/multiclass\n",
    "precision = precision_score(y, test_data_pred, average='macro')  # Adjust for binary/multiclass\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
